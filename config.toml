# base_url = "http://180.213.184.177:30084/v1"
# api_key = 'Empty'
# model = "DeepSeek-R1-0528-AWQ"

# base_url = "http://113.140.77.91:1025/v1"
# api_key = "Empty"
# model = "deepseekv3"

base_url = "http://180.213.184.182:30083/v1"
api_key = "Empty"
model = "DeepSeek-R1-0528-AWQ"

# base_url = "http://180.213.184.182:30082/v1"
# api_key = "Empty"
# model = "Qwen3-32B"

# base_url = "http://180.213.184.153:30084/v1"
# api_key = "Empty"
# model = "qwen3-235b"

# base_url = "http://180.213.184.153:30082/v1"
# api_key = "Empty"
# model = "qwen3-14b"

# base_url = "https://api.deepseek.com"
# api_key = "sk-47c6b7385f4d4e47af1969f6c99f2d4d"
# model = "deepseek-reasoner"

# base_url = 'https://openrouter.ai/api/v1'
# api_key="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"
# model="openai/gpt-4o"

input_question_excel_file = 'QA_tables.xlsx'
goldens_question_jsonl_file = 'golden_questions.jsonl'
reference_model_name = "openai/o3"
goldens_QA_jsonl_file = 'QA_goldens.jsonl'
goldens_QA_excel_file = 'QA_goldens.xlsx'

model_names = [
    "新奥QA测试-32B蒸馏",
    "新奥QA测试-14B蒸馏",
    "deepseek/deepseek-r1",
    "openai/gpt-4.1",
    "openai/o3",
    "anthropic/claude-sonnet-4",
    "google/gemini-2.5-pro-preview",
    "x-ai/grok-3-beta",
]
QA_file_name = "QA_tables.xlsx"
base_model_id = 1
trained_model_id = 2
[alternative_names]
"新奥QA测试-32B蒸馏" = "DeepSeek-R1-Distill-Qwen-32B"
"新奥QA测试-14B蒸馏" = "DeepSeek-R1-Distill-Qwen-14B"

[llm_judge_config]
max_workers = 64
timeout = 500

# Openrouter
# LLM_judge_model = "openai/gpt-4.1"
# LLM_judge_model = "openai/gpt-4o-mini"

# DeepSeek
# LLM_judge_model = "deepseek-reasoner"
# LLM_judge_model = "deepseek-chat"

# Qwen (local deployment)
# LLM_judge_model = "qwen3-235B"
LLM_judge_model = "Qwen3-32B"
# LLM_judge_model = "deepseek-r1-250120"

embedding_model = "bge-m3"

[serverchan]
SENDKEY = "SCT282544TL0OGujmTDvM8IjUNxud8UndW"