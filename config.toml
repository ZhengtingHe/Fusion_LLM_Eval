model_names = [
    "新奥QA测试-32B蒸馏",
    "新奥QA测试-14B蒸馏",
    "deepseek/deepseek-r1",
    "openai/gpt-4.1",
    "openai/o3",
    "anthropic/claude-sonnet-4",
    "google/gemini-2.5-pro-preview",
    "x-ai/grok-3-beta",
]
QA_file_name = "QA_tables.xlsx"
# alternative_names :
#     # 新奥QA测试-32B蒸馏 : deepseek-ai/DeepSeek-R1-Distill-Qwen-32B,
#     # 新奥QA测试-14B蒸馏 : deepseek-ai/DeepSeek-R1-Distill-Qwen-14B,
#     新奥QA测试-32B蒸馏 : DeepSeek-R1-Distill-Qwen-32B
#     新奥QA测试-14B蒸馏 : DeepSeek-R1-Distill-Qwen-14B
# The above YAML comments and structure for alternative_names don't translate directly to a simple TOML table
# if the intent was to have specific key-value pairs uncommented.
# Assuming the last two lines were the intended active configuration:
[alternative_names]
"新奥QA测试-32B蒸馏" = "DeepSeek-R1-Distill-Qwen-32B"
"新奥QA测试-14B蒸馏" = "DeepSeek-R1-Distill-Qwen-14B"

[llm_judge_config]
max_workers = 64
timeout = 500

# Openrouter
# LLM_judge_model = "openai/gpt-4.1"
# LLM_judge_model = "openai/gpt-4o-mini"

# DeepSeek
# LLM_judge_model = "deepseek-reasoner"
# LLM_judge_model = "deepseek-chat"

# Qwen (local deployment)
# LLM_judge_model = "qwen3-235B"
LLM_judge_model = "Qwen3-32B"
# LLM_judge_model = "deepseek-r1-250120"

embedding_model = "bge-m3"