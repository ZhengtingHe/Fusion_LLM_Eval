# base_url = "http://180.213.184.177:30084/v1"
# api_key = 'Empty'
# model = "DeepSeek-R1-0528-AWQ"

# base_url = "http://113.140.77.91:1025/v1"
# api_key = "Empty"
# model = "deepseekv3"

base_url = "http://180.213.184.177:30084/v1"
api_key = "Empty"
model = "deepseek-r1"

# base_url = "https://api.deepseek.com"
# api_key = "sk-47c6b7385f4d4e47af1969f6c99f2d4d"
# model = "deepseek-reasoner"

model_names = [
    "新奥QA测试-32B蒸馏",
    "新奥QA测试-14B蒸馏",
    "deepseek/deepseek-r1",
    "openai/gpt-4.1",
    "openai/o3",
    "anthropic/claude-sonnet-4",
    "google/gemini-2.5-pro-preview",
    "x-ai/grok-3-beta",
]
QA_file_name = "QA_tables.xlsx"
[alternative_names]
"新奥QA测试-32B蒸馏" = "DeepSeek-R1-Distill-Qwen-32B"
"新奥QA测试-14B蒸馏" = "DeepSeek-R1-Distill-Qwen-14B"

[llm_judge_config]
max_workers = 64
timeout = 500

# Openrouter
# LLM_judge_model = "openai/gpt-4.1"
# LLM_judge_model = "openai/gpt-4o-mini"

# DeepSeek
# LLM_judge_model = "deepseek-reasoner"
# LLM_judge_model = "deepseek-chat"

# Qwen (local deployment)
# LLM_judge_model = "qwen3-235B"
LLM_judge_model = "Qwen3-32B"
# LLM_judge_model = "deepseek-r1-250120"

embedding_model = "bge-m3"