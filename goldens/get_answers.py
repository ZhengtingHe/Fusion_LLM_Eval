import pandas as pd
import json
import asyncio
from pathlib import Path
import toml
from tqdm import tqdm
from collections import defaultdict

# LangChain specific imports
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- âš™ï¸ 1. CONFIGURATION (æ— å˜åŒ–) ---
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent
with open(project_root / 'config.toml', 'r', encoding='utf-8') as toml_file:
    config = toml.load(toml_file)
goldens_path = project_root / 'goldens'
input_jsonl_path = goldens_path / config['goldens_question_jsonl_file']
print(f"Input JSONL file: {input_jsonl_path}")
output_excel_path = goldens_path / config['goldens_QA_excel_file']

# LLM API Configuration
BASE_URL = config['base_url']
API_KEY = config['api_key']
MODEL_NAME = config['model']
SYSTEM_PROMPT: str = Path(project_root / "system_prompt.md").read_text(encoding="utf-8")

# --- â›“ï¸ 2. LANGCHAIN SETUP (æ— å˜åŒ–) ---
prompt = ChatPromptTemplate.from_messages([
    ("system", SYSTEM_PROMPT),
    ("user", "{question}")
])
model = ChatOpenAI(
    model=MODEL_NAME,
    api_key=API_KEY,
    base_url=BASE_URL,
    temperature=0.5,
)
output_parser = StrOutputParser()
chain = prompt | model | output_parser


# --- ğŸš€ 3. MAIN ASYNC EXECUTION LOGIC (å…¨æ–°ä¿®æ”¹) ---
async def main():
    """
    Main async function using asyncio.gather for robust parallel processing.
    """
    try:
        with open(input_jsonl_path, 'r', encoding='utf-8') as f:
            questions = [json.loads(line) for line in f]
        print(f"âœ… Successfully loaded {len(questions)} questions from '{input_jsonl_path}'.")
    except FileNotFoundError:
        print(f"âŒ ERROR: Input file not found. Please run the data generation script first.")
        return

    inputs = [{"question": q.get("é—®é¢˜", "")} for q in questions]

    # --- å…¨æ–°çš„å¸¦è¿›åº¦æ¡çš„å¹¶å‘é€»è¾‘ ---

    # 1. åˆå§‹åŒ–tqdmè¿›åº¦æ¡
    pbar = tqdm(total=len(inputs), desc="è·å–å›ç­”ä¸­")

    # 2. å®šä¹‰ä¸€ä¸ªç®€å•çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºåœ¨æ¯ä¸ªä»»åŠ¡å®Œæˆæ—¶æ›´æ–°è¿›åº¦æ¡
    def update_progress(future):
        pbar.update(1)

    # 3. åˆ›å»ºæ‰€æœ‰ä»»åŠ¡ï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡é™„åŠ å®Œæˆå›è°ƒ
    tasks = []
    for inp in inputs:
        # åˆ›å»ºä»»åŠ¡
        task = asyncio.create_task(chain.ainvoke(inp))
        # é™„åŠ å›è°ƒ
        task.add_done_callback(update_progress)
        tasks.append(task)

    print(f"ğŸš€ Sending {len(inputs)} requests to the LLM in parallel...")

    # 4. ä½¿ç”¨ asyncio.gather å¹¶å‘è¿è¡Œæ‰€æœ‰ä»»åŠ¡
    #    return_exceptions=True æ˜¯ä¸€ä¸ªå…³é”®å‚æ•°ï¼Œå®ƒèƒ½ç¡®ä¿å³ä½¿éƒ¨åˆ†ä»»åŠ¡å¤±è´¥ï¼Œ
    #    gatherä¹Ÿä¸ä¼šç«‹å³ä¸­æ–­ï¼Œè€Œæ˜¯å°†å¼‚å¸¸ä½œä¸ºç»“æœè¿”å›ã€‚
    answers = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 5. æ‰€æœ‰ä»»åŠ¡å®Œæˆåï¼Œå…³é—­è¿›åº¦æ¡
    pbar.close()

    # --- åç»­é€»è¾‘ä¸å˜ï¼Œä½†å¢åŠ äº†å¯¹å¼‚å¸¸çš„å¤„ç† ---

    print("\nâœ… All questions have been processed.")

    # å°†ç»“æœåˆå¹¶å›åŸå§‹æ•°æ®
    for i, question_data in enumerate(questions):
        result = answers[i]
        # æ£€æŸ¥è¿”å›çš„ç»“æœæ˜¯å¦æ˜¯ä¸€ä¸ªå¼‚å¸¸å¯¹è±¡
        if isinstance(result, Exception):
            question_data["å›ç­”"] = f"ERROR: {result}"
        else:
            question_data["å›ç­”"] = result

    # --- ğŸ’¾ 4. SAVING TO EXCEL (å…¨æ–°ä¿®æ”¹) ---

    # 4a. æŒ‰â€œé¢†åŸŸâ€å¯¹ç»“æœè¿›è¡Œåˆ†ç»„
    grouped_by_domain = defaultdict(list)
    for qa_pair in questions:
        domain = qa_pair.get("é¢†åŸŸ", "æœªåˆ†ç±»") # å¦‚æœæ²¡æœ‰é¢†åŸŸï¼Œåˆ™å½’ä¸ºâ€œæœªåˆ†ç±»â€
        grouped_by_domain[domain].append(qa_pair)

    # 4b. ä½¿ç”¨ExcelWriterå°†æ¯ä¸ªç»„å†™å…¥ä¸€ä¸ªå•ç‹¬çš„sheet
    try:
        with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:
            print(f"âœï¸ Saving results to '{output_excel_path}' with multiple sheets...")
            
            # éå†æ¯ä¸ªé¢†åŸŸåŠå…¶å¯¹åº”çš„æ•°æ®
            for domain, data_list in grouped_by_domain.items():
                # ä¸ºå½“å‰é¢†åŸŸåˆ›å»ºä¸€ä¸ªDataFrame
                df_domain = pd.DataFrame(data_list)
                
                # å®šä¹‰å¹¶ç­›é€‰åˆ—é¡ºåºï¼ˆä¸å†éœ€è¦â€œé¢†åŸŸâ€åˆ—ï¼Œå› ä¸ºå®ƒå·²ç»æ˜¯sheetåï¼‰
                cols = ["é—®é¢˜", "å›ç­”", "å®¢è§‚åˆ†ç±»", "çŸ¥è¯†ç‚¹", "ä¸»è§‚éš¾æ˜“åº¦", "åº”ç”¨åœºæ™¯"]
                df_domain = df_domain[[c for c in cols if c in df_domain.columns]]
                
                # Excelçš„sheetåæœ‰å­—ç¬¦é™åˆ¶ï¼ˆå¦‚é•¿åº¦ä¸èƒ½è¶…è¿‡31ï¼‰ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€å•çš„æˆªæ–­
                sheet_name = domain[:31]
                
                # å°†DataFrameå†™å…¥æŒ‡å®šåç§°çš„sheet
                df_domain.to_excel(writer, sheet_name=sheet_name, index=False)
                
        print(f"âœ… Successfully saved results. Each domain is now a separate sheet in the Excel file.")
    except Exception as e:
        print(f"âŒ ERROR: Failed to save results to Excel. {e}")


if __name__ == "__main__":
    asyncio.run(main())